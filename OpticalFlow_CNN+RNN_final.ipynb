{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpticalFlow_CNN+RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asFr_CPuJwBI",
        "outputId": "c74c32f3-53c2-4e25-bb2b-4c78fc877901"
      },
      "source": [
        "#Mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itXY9fyO2oLV"
      },
      "source": [
        "#Command to connect to local runtime\n",
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmTlp_jjUVwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e39e5d6-52a5-4898-ee5c-84e6da5e19a5"
      },
      "source": [
        "pip install face_recognition"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 1.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=67b8b0f0eb9eb6ae5de46c5c6e31296a61b6a8811dcf1adc954033d7a6286fa0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "import random\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "import random\n",
        "import keras\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import LSTM\n",
        "from scipy import stats as s\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "zDErLVYjXhDn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfb0J5_GUkj3",
        "outputId": "292ad01d-73d4-4f27-edff-0eab0d5147e1"
      },
      "source": [
        "#Adding the datasets \n",
        "#Change the path to the specified datasets accordingly\n",
        "\n",
        "#DFDC Dataset \n",
        "video_files = glob.glob('/content/drive/MyDrive/FinalDatasets/DFDC_FAKE_Face_only_data/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/FinalDatasets/DFDC_REAL_Face_only_data/*.mp4')\n",
        "\n",
        "#Uncomment for Celeb DF dataset\n",
        "#video_files = glob.glob('/content/drive/MyDrive/FinalDatasets/Celeb_fake_face_only/*.mp4')\n",
        "#video_files += glob.glob('/content/drive/MyDrive/FinalDatasets/Celeb_real_face_only/*.mp4')\n",
        "\n",
        "#Uncomment for FaceForensics++ Dataset\n",
        "#video_files = glob.glob('/content/drive/MyDrive/FinalDatasets/FF_Face_only_data/*.mp4')\n",
        "\n",
        "random.shuffle(video_files)\n",
        "random.shuffle(video_files)\n",
        "frame_count = []\n",
        "\n",
        "#calculating the total videos in the complete dataset and average frames per video\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<148):\n",
        "    video_files.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"frames are \" , frame_count)\n",
        "print(\"Total no of video: \" , len(frame_count))\n",
        "print('Average frame per video:',np.mean(frame_count))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frames are  [148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
            "Total no of video:  3067\n",
            "Average frame per video: 148.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZXHDejUrCp"
      },
      "source": [
        "#Function to count the number of fake and real videos\n",
        "def number_of_real_and_fake_videos(data_list):\n",
        "  header_list = [\"file\",\"label\"]\n",
        "  #Change the path to Gobal_metadata.csv file accordingly\n",
        "  lab = pd.read_csv('/content/drive/MyDrive/Gobal_metadata.csv',names=header_list)\n",
        "  fake = 0\n",
        "  real = 0\n",
        "  for i in data_list:\n",
        "    temp_video = i.split('/')[-1]\n",
        "    label = lab.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "    if(label == 'FAKE'):\n",
        "      fake+=1\n",
        "    if(label == 'REAL'):\n",
        "      real+=1\n",
        "  return real,fake"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "header_list = [\"file\",\"label\"]\n",
        "#Change the path to Gobal_metadata.csv file accordingly\n",
        "labels = pd.read_csv('/content/drive/MyDrive/Gobal_metadata.csv',names=header_list)\n",
        "\n",
        "#splitting the video_files into train_videos and valis_videos in 80:20 ratio\n",
        "train_videos = video_files[:int(0.8*len(video_files))]\n",
        "valid_videos = video_files[int(0.8*len(video_files)):]\n",
        "\n",
        "#Printing total number of videos in train and test videos\n",
        "print(\"TOTAL TRAIN VIDEOS : \" , len(train_videos))\n",
        "print(\"TOTAL TEST VIDEOS : \" , len(valid_videos))\n",
        "\n",
        "print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(train_videos)[0],\" Fake:\",number_of_real_and_fake_videos(train_videos)[1])\n",
        "print(\"TEST: \", \"Real:\",number_of_real_and_fake_videos(valid_videos)[0],\" Fake:\",number_of_real_and_fake_videos(valid_videos)[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCL7Ws-AiyEl",
        "outputId": "21b7b753-eb0d-48ac-de2b-fc0f43e37bb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOTAL TRAIN VIDEOS :  2544\n",
            "TOTAL TEST VIDEOS :  636\n",
            "TRAIN:  Real: 1343  Fake: 1201\n",
            "TEST:  Real: 351  Fake: 285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH02LJigXsRX"
      },
      "source": [
        "samples=[]\n",
        "label_lists=[] \n",
        "\n",
        "#Function to calculate Optical flow\n",
        "\n",
        "def get_opticalflow(file,frame_per_video) :\n",
        "  # The video feed is read in as a VideoCapture object\n",
        "  cap = cv.VideoCapture(file)\n",
        "\n",
        "  #splitting the file path to get the names of the videos\n",
        "  #change the split function according to your file path\n",
        "  temp_video = file.split('/')[-1]\n",
        "\n",
        "  #Change the path to Gobal_metadata.csv file accordingly\n",
        "  labels = pd.read_csv('/content/drive/MyDrive/Gobal_metadata.csv',names=header_list)\n",
        "\n",
        "  #getting the labels from Gobal_metadata.csv file\n",
        "  label = labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "  if(label == 'FAKE'):\n",
        "    label = 0\n",
        "  if(label == 'REAL'):\n",
        "    label = 1\n",
        "  \n",
        "  # ret = a boolean return value from\n",
        "  # getting the frame, first_frame = the\n",
        "  # first frame in the entire video sequence\n",
        "  ret, first_frame = cap.read()\n",
        "\n",
        "  # Converts frame to grayscale because we\n",
        "  # only need the luminance channel for\n",
        "  # detecting edges - less computationally\n",
        "  # expensive\n",
        "  prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Creates an image filled with zero\n",
        "  # intensities with the same dimensions\n",
        "  # as the frame\n",
        "  mask = np.zeros_like(first_frame)\n",
        "\n",
        "  #setting the frame count to 0\n",
        "  count=0\n",
        "  # Sets image saturation to maximum\n",
        "  mask[..., 1] = 255\n",
        "  \n",
        "  while(cap.isOpened()):\n",
        "    #appending the labels of the frames\n",
        "    label_lists.append(label)\n",
        "\n",
        "    # ret = a boolean return value from getting\n",
        "    # the frame, frame = the current frame being\n",
        "    # projected in the video\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if ret==True :\n",
        "      # Converts each frame to grayscale - we previously\n",
        "      # only converted the first frame to grayscale\n",
        "      gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    \n",
        "      # Calculates dense optical flow by Farneback method\n",
        "      flow = cv.calcOpticalFlowFarneback(prev_gray, gray,\n",
        "                      None,\n",
        "                      0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    \n",
        "      # Computes the magnitude and angle of the 2D vectors\n",
        "      magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    \n",
        "      # Sets image hue according to the optical flow\n",
        "      # direction\n",
        "      mask[..., 0] = angle * 180 / np.pi / 2\n",
        "    \n",
        "      # Sets image value according to the optical flow\n",
        "      # magnitude (normalized)\n",
        "      mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)\n",
        "    \n",
        "      # Converts HSV to RGB (BGR) color representation\n",
        "      rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)\n",
        "    \n",
        "      #appending the rgb frames to samples\n",
        "      samples.append(rgb)\n",
        " \n",
        "      # Updates previous frame\n",
        "      prev_gray = gray\n",
        "\n",
        "    #updates the frame count\n",
        "    count=count+1\n",
        "    \n",
        "    #if the frame_count limit is reached the loop breaks and moves to next video\n",
        "    if count==frame_per_video:\n",
        "      break\n",
        "\n",
        "  # The following frees up resources and\n",
        "  # closes all windows\n",
        "  cap.release()\n",
        "  cv.destroyAllWindows()\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01FSAMxcX1pr"
      },
      "source": [
        "#defining the number of frames to retrieve from each video\n",
        "frame_per_video=148\n",
        "\n",
        "#Generating the optical flow of the videos in train_videos\n",
        "for i in train_videos:\n",
        "  get_opticalflow(i,frame_per_video)\n",
        "\n",
        "#converting the samples(frames list) to numpy array\n",
        "x=np.array(samples) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBFa1Eve_Brk"
      },
      "source": [
        "y = label_lists\n",
        "\n",
        "#creating the training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2, stratify = y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzXXpagwd6YI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823a5645-5927-4bab-9cc6-b40243685c70"
      },
      "source": [
        "#printing the shape of X_train\n",
        "print(X_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20384, 112, 112, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEG9hlIQeO09"
      },
      "source": [
        "# creating dummies of target variable for train and validation set\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MUDBKgjeYoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4ca7f2-c727-43b8-96e9-e151326911be"
      },
      "source": [
        "# creating the base model of pre-trained VGG16 model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfFPBKbKe_hK"
      },
      "source": [
        "# extracting features for training frames\n",
        "X_train = base_model.predict(X_train)\n",
        "# extracting features for validation frames\n",
        "X_test = base_model.predict(X_test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INDBhHwFfhxY"
      },
      "source": [
        "# reshaping the training as well as validation frames in single dimension\n",
        "# change the shapes of X_train and X_test accordingly\n",
        "X_train = X_train.reshape(X_train.shape[0], 3*3*512)\n",
        "X_test = X_test.reshape(X_test.shape[0], 3*3*512)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UA2nvQYfsEa"
      },
      "source": [
        "# normalizing the pixel values\n",
        "max = X_train.max()\n",
        "X_train = X_train/max\n",
        "X_test = X_test/max"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcUdS0_Xz5l-"
      },
      "source": [
        "X_train = X_train.reshape(len(X_train), 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(len(X_test), 1, X_test.shape[1])\n",
        "y_train_new=y_train.to_numpy()\n",
        "y_test_new=y_test.to_numpy()\n",
        "y_test_new = y_test_new.reshape(len(y_test_new), 1, y_test_new.shape[1])\n",
        "y_train_new = y_train_new.reshape(len(y_train_new), 1, y_train_new.shape[1])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et8h_Zfvfyty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc6c184-bf5c-4abd-b3ca-f82397d91f44"
      },
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Recurrent layer\n",
        "model.add(LSTM(128,input_shape=(X_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(LSTM(128,input_shape=(X_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnozyxvPf798"
      },
      "source": [
        "# defining a function to save the weights of best model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f95MUwc4f_y9"
      },
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fz79x-JgKeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b8ff226-f8f7-4257-dcf9-78915357464d"
      },
      "source": [
        "# training the model\n",
        "model.fit(X_train, y_train_new, epochs=30, validation_data=(X_test, y_test_new), callbacks=[mcp_save], batch_size=128)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "160/160 [==============================] - 6s 18ms/step - loss: 0.6802 - accuracy: 0.5559 - val_loss: 0.6652 - val_accuracy: 0.6056\n",
            "Epoch 2/30\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.6550 - accuracy: 0.6034 - val_loss: 0.6464 - val_accuracy: 0.6281\n",
            "Epoch 3/30\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.6292 - accuracy: 0.6367 - val_loss: 0.6403 - val_accuracy: 0.6291\n",
            "Epoch 4/30\n",
            "160/160 [==============================] - 2s 16ms/step - loss: 0.6023 - accuracy: 0.6684 - val_loss: 0.6446 - val_accuracy: 0.6336\n",
            "Epoch 5/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.5747 - accuracy: 0.6913 - val_loss: 0.6426 - val_accuracy: 0.6262\n",
            "Epoch 6/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.5342 - accuracy: 0.7254 - val_loss: 0.6449 - val_accuracy: 0.6415\n",
            "Epoch 7/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.4843 - accuracy: 0.7619 - val_loss: 0.6768 - val_accuracy: 0.6328\n",
            "Epoch 8/30\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.4378 - accuracy: 0.7929 - val_loss: 0.7384 - val_accuracy: 0.6291\n",
            "Epoch 9/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3884 - accuracy: 0.8230 - val_loss: 0.7278 - val_accuracy: 0.6246\n",
            "Epoch 10/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.3422 - accuracy: 0.8459 - val_loss: 0.8416 - val_accuracy: 0.6270\n",
            "Epoch 11/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2965 - accuracy: 0.8710 - val_loss: 0.9486 - val_accuracy: 0.6250\n",
            "Epoch 12/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2566 - accuracy: 0.8926 - val_loss: 0.8953 - val_accuracy: 0.6295\n",
            "Epoch 13/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.2200 - accuracy: 0.9117 - val_loss: 1.0318 - val_accuracy: 0.6303\n",
            "Epoch 14/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.1957 - accuracy: 0.9199 - val_loss: 1.0638 - val_accuracy: 0.6266\n",
            "Epoch 15/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.1697 - accuracy: 0.9320 - val_loss: 1.1063 - val_accuracy: 0.6315\n",
            "Epoch 16/30\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.1509 - accuracy: 0.9404 - val_loss: 1.2115 - val_accuracy: 0.6172\n",
            "Epoch 17/30\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.1381 - accuracy: 0.9458 - val_loss: 1.1131 - val_accuracy: 0.6315\n",
            "Epoch 18/30\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.1238 - accuracy: 0.9529 - val_loss: 1.1418 - val_accuracy: 0.6293\n",
            "Epoch 19/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.1116 - accuracy: 0.9580 - val_loss: 1.2230 - val_accuracy: 0.6279\n",
            "Epoch 20/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.1017 - accuracy: 0.9606 - val_loss: 1.3957 - val_accuracy: 0.6258\n",
            "Epoch 21/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0981 - accuracy: 0.9635 - val_loss: 1.1843 - val_accuracy: 0.6236\n",
            "Epoch 22/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0867 - accuracy: 0.9683 - val_loss: 1.4238 - val_accuracy: 0.6317\n",
            "Epoch 23/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0871 - accuracy: 0.9683 - val_loss: 1.3535 - val_accuracy: 0.6272\n",
            "Epoch 24/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0710 - accuracy: 0.9737 - val_loss: 1.6725 - val_accuracy: 0.6234\n",
            "Epoch 25/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0735 - accuracy: 0.9714 - val_loss: 1.5022 - val_accuracy: 0.6303\n",
            "Epoch 26/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0753 - accuracy: 0.9730 - val_loss: 1.6351 - val_accuracy: 0.6238\n",
            "Epoch 27/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0683 - accuracy: 0.9771 - val_loss: 1.4718 - val_accuracy: 0.6334\n",
            "Epoch 28/30\n",
            "160/160 [==============================] - 2s 14ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 1.7308 - val_accuracy: 0.6242\n",
            "Epoch 29/30\n",
            "160/160 [==============================] - 2s 15ms/step - loss: 0.0619 - accuracy: 0.9762 - val_loss: 1.5974 - val_accuracy: 0.6262\n",
            "Epoch 30/30\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.0606 - accuracy: 0.9779 - val_loss: 1.5862 - val_accuracy: 0.6338\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff36627aed0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDCTKdz8AzvC"
      },
      "source": [
        "Evaluating our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-QNh4LuhuIm"
      },
      "source": [
        "# loading the trained weights \n",
        "#Enter the path accordingly\n",
        "model.load_weights(\"weight.hdf5\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrjW_sbdhzYJ"
      },
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#valid_label.clear\n",
        "#del df\n",
        "#del y"
      ],
      "metadata": {
        "id": "aaf1r0dHB1Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3PFQUIO_q_H"
      },
      "source": [
        "# creating dataframe for actual labels of the valid_videos\n",
        "valid_label =[]\n",
        "\n",
        "for video_file in valid_videos :\n",
        "    count = 0\n",
        "    videoFile = video_file\n",
        "    cap = cv2.VideoCapture(video_file)   # capturing the video from the given path\n",
        "\n",
        "    # Splitting the file path of videos to get their names \n",
        "    #can be changed accordingly\n",
        "    temp_video = video_file.split('/')[-1] \n",
        "\n",
        "    # Change the path to Gobal_metadata.csv accordingly\n",
        "    labels = pd.read_csv('/content/drive/MyDrive/Gobal_metadata.csv',names=header_list)\n",
        "    label = labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "    if(label == 'FAKE'):\n",
        "      label = 0\n",
        "    if(label == 'REAL'):\n",
        "      label = 1\n",
        "    label_str = str(label)\n",
        "    valid_label.append(label_str)\n",
        "            \n",
        "df = pd.DataFrame(valid_label)\n",
        "y = pd.get_dummies(df)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYZahHf0Cep5"
      },
      "source": [
        "While re-running the code, execute predit.clear to clear the list of previously predicted labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQaT8hszh4do"
      },
      "source": [
        "predict=[]\n",
        "\n",
        "def predicting(file,frame_per_video) :\n",
        "  prediction_images=[]\n",
        "  count=0 \n",
        "  # The video feed is read in as\n",
        "  # a VideoCapture object\n",
        "  cap = cv.VideoCapture(file)\n",
        "  \n",
        "  # ret = a boolean return value from\n",
        "  # getting the frame, first_frame = the\n",
        "  # first frame in the entire video sequence\n",
        "  ret, first_frame = cap.read()\n",
        "\n",
        "  # Converts frame to grayscale because we\n",
        "  # only need the luminance channel for\n",
        "  # detecting edges - less computationally\n",
        "  # expensive\n",
        "  prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Creates an image filled with zero\n",
        "  # intensities with the same dimensions\n",
        "  # as the frame\n",
        "  mask = np.zeros_like(first_frame)\n",
        "  \n",
        "  # Sets image saturation to maximum\n",
        "  mask[..., 1] = 255\n",
        "  \n",
        "  while(cap.isOpened()):\n",
        "    \n",
        "    # ret = a boolean return value from getting\n",
        "    # the frame, frame = the current frame being\n",
        "    # projected in the video\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    \n",
        "    if ret==True :\n",
        "      # Converts each frame to grayscale - we previously\n",
        "      # only converted the first frame to grayscale\n",
        "      gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    \n",
        "      # Calculates dense optical flow by Farneback method\n",
        "      flow = cv.calcOpticalFlowFarneback(prev_gray, gray,\n",
        "                      None,\n",
        "                      0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    \n",
        "      # Computes the magnitude and angle of the 2D vectors\n",
        "      magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    \n",
        "      # Sets image hue according to the optical flow\n",
        "      # direction\n",
        "      mask[..., 0] = angle * 180 / np.pi / 2\n",
        "    \n",
        "      # Sets image value according to the optical flow\n",
        "      # magnitude (normalized)\n",
        "      mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)\n",
        "    \n",
        "      # Converts HSV to RGB (BGR) color representation\n",
        "      rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)\n",
        "    \n",
        "      #appending the rgb images \n",
        "      prediction_images.append(rgb)\n",
        "    \n",
        "      # Updates previous frame\n",
        "      prev_gray = gray\n",
        "    count=count+1\n",
        "    # Frames are read by intervals of 1 millisecond. The\n",
        "    # programs breaks out of the while loop when the\n",
        "    # user presses the 'q' key\n",
        "    if count==frame_per_video:\n",
        "      break\n",
        "\n",
        "  # The following frees up resources and closes all windows\n",
        "  cap.release()\n",
        "  cv.destroyAllWindows()\n",
        "  # converting all the frames for a test video into numpy array\n",
        "  prediction_images = np.array(prediction_images)\n",
        "\n",
        "  # extracting features using pre-trained model\n",
        "  prediction_images = base_model.predict(prediction_images)\n",
        " \n",
        "  # converting features in one dimensional array\n",
        "  prediction_images = prediction_images.reshape(prediction_images.shape[0], 3*3*512)\n",
        "\n",
        "  prediction_images = prediction_images.reshape(len(prediction_images), 1, prediction_images.shape[1])\n",
        "\n",
        "  # predicting tags for each array\n",
        "  prediction = np.argmax(model.predict(prediction_images),axis=-1)\n",
        "\n",
        "  prediction_new= pd.DataFrame(prediction)\n",
        "  g = s.mode(prediction_new)[0][0]\n",
        "  k=g[0]\n",
        "  # appending the mode of predictions in predict list to assign the tag to the video\n",
        "  predict.append(y.columns.values[k].split('_')[-1])\n",
        "  \n",
        "  "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict.clear"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDgCtYCilSfZ",
        "outputId": "79df988a-9911-46e9-b858-022d1f7cb1aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function list.clear>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyS9oKGDTWbx"
      },
      "source": [
        "#predicting the videos over the trained model\n",
        "for i in valid_videos :\n",
        "  predicting(i,frame_per_video)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLpAQ2lqIq7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90afc836-aa58-4674-c357-3b51fb4a86d0"
      },
      "source": [
        "accuracy_metric=accuracy_score(predict, valid_label)\n",
        "print(\"Accuracy score : \", accuracy_metric*100)\n",
        "\n",
        "precision_metric=precision_score(valid_label, predict, average = \"macro\")\n",
        "print(\"Precision score : \", precision_metric*100)\n",
        "\n",
        "recall_metric = recall_score(valid_label, predict, average = \"macro\")\n",
        "print(\"Recall score : \",recall_metric*100)\n",
        "\n",
        "\n",
        "f1_metric = f1_score(valid_label, predict, average = \"macro\")\n",
        "print(\"F1 score : \", f1_metric*100)\n",
        "\n",
        "# calculate roc curve\n",
        "#fpr, tpr, thresholds = roc_curve(valid_label, predict)\n",
        "# calculate AUC\n",
        "auc = roc_auc_score(valid_label, predict)\n",
        "print(\"ROC AUC score : \",auc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score :  61.852433281004714\n",
            "Precision score :  62.09795394881866\n",
            "Recall score :  61.90307188769273\n",
            "F1 score :  61.71619365609349\n",
            "ROC AUC score :  0.6190307188769274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:546: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  y_score = check_array(y_score, ensure_2d=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_label = [int(i) for i in valid_label]\n",
        "predict = [int(i) for i in predict]"
      ],
      "metadata": {
        "id": "YMim1lauOy6P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_fpr, lr_tpr, _ = roc_curve(valid_label, predict)\n",
        "plt.subplots(1, figsize=(6,6))\n",
        "plt.title('ROC curve of the model')\n",
        "plt.plot(lr_fpr, lr_tpr, color=\"#db7807\")\n",
        "plt.plot([0, 1], ls=\"--\", color=\"orange\")\n",
        "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "sw7oSUXTTark",
        "outputId": "dc94908f-3621-4c8f-bc70-7ab19946b22f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}