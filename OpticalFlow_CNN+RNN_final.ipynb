{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpticalFlow_CNN+RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asFr_CPuJwBI",
        "outputId": "ebd3b74b-8750-46d0-e277-63990e918c97"
      },
      "source": [
        "#Mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itXY9fyO2oLV"
      },
      "source": [
        "#Command to connect to local runtime\n",
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmTlp_jjUVwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ed057b-56dc-44ff-c905-1c25899b4513"
      },
      "source": [
        "pip install face_recognition"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=1a41cacc05153006c3f604fc9774a3dd4aeb7e3c8fe1819b1311cb061119c46d\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "import random\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "import random\n",
        "import keras\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import LSTM\n",
        "from scipy import stats as s\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "zDErLVYjXhDn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfb0J5_GUkj3",
        "outputId": "c92ecf3a-5355-41e4-d139-474cc8582884"
      },
      "source": [
        "#Adding the datasets \n",
        "#Change the path to the specified datasets accordingly\n",
        "\n",
        "#DFDC Dataset \n",
        "video_files = glob.glob('/content/drive/MyDrive/FinalDatasets/DFDC_FAKE_Face_only_data/*.mp4')\n",
        "video_files += glob.glob('/content/drive/MyDrive/FinalDatasets/DFDC_REAL_Face_only_data/*.mp4')\n",
        "\n",
        "#Uncomment for Celeb DF dataset\n",
        "#video_files = glob.glob('/content/drive/MyDrive/FinalDatasets/Celeb_fake_face_only/*.mp4')\n",
        "#video_files += glob.glob('/content/drive/MyDrive/FinalDatasets/Celeb_real_face_only/*.mp4')\n",
        "\n",
        "#Uncomment for FaceForensics++ Dataset\n",
        "#video_files = glob.glob('/content/drive/MyDrive/FinalDatasets/FF_Face_only_data/*.mp4')\n",
        "\n",
        "random.shuffle(video_files)\n",
        "random.shuffle(video_files)\n",
        "frame_count = []\n",
        "\n",
        "#calculating the total videos in the complete dataset and average frames per video\n",
        "for video_file in video_files:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<148):\n",
        "    video_files.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"frames are \" , frame_count)\n",
        "print(\"Total no of video: \" , len(frame_count))\n",
        "print('Average frame per video:',np.mean(frame_count))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frames are  [148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148, 148]\n",
            "Total no of video:  1154\n",
            "Average frame per video: 148.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrZXHDejUrCp"
      },
      "source": [
        "#Function to count the number of fake and real videos\n",
        "def number_of_real_and_fake_videos(data_list):\n",
        "  header_list = [\"file\",\"label\"]\n",
        "  #Change the path to Gobal_metadata.csv file accordingly\n",
        "  lab = pd.read_csv('/content/drive/MyDrive/Gobal_metadata.csv',names=header_list)\n",
        "  fake = 0\n",
        "  real = 0\n",
        "  for i in data_list:\n",
        "    temp_video = i.split('/')[-1]\n",
        "    label = lab.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "    if(label == 'FAKE'):\n",
        "      fake+=1\n",
        "    if(label == 'REAL'):\n",
        "      real+=1\n",
        "  return real,fake"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "header_list = [\"file\",\"label\"]\n",
        "#Change the path to Gobal_metadata.csv file accordingly\n",
        "labels = pd.read_csv('/content/drive/MyDrive/Gobal_metadata.csv',names=header_list)\n",
        "\n",
        "#splitting the video_files into train_videos and valis_videos in 80:20 ratio\n",
        "train_videos = video_files[:int(0.8*len(video_files))]\n",
        "valid_videos = video_files[int(0.8*len(video_files)):]\n",
        "\n",
        "#Printing total number of videos in train and test videos\n",
        "print(\"TOTAL TRAIN VIDEOS : \" , len(train_videos))\n",
        "print(\"TOTAL TEST VIDEOS : \" , len(valid_videos))\n",
        "\n",
        "print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(train_videos)[0],\" Fake:\",number_of_real_and_fake_videos(train_videos)[1])\n",
        "print(\"TEST: \", \"Real:\",number_of_real_and_fake_videos(valid_videos)[0],\" Fake:\",number_of_real_and_fake_videos(valid_videos)[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCL7Ws-AiyEl",
        "outputId": "a5ffc03e-a563-4b1b-b7c0-7977b22ee4de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOTAL TRAIN VIDEOS :  928\n",
            "TOTAL TEST VIDEOS :  233\n",
            "TRAIN:  Real: 465  Fake: 463\n",
            "TEST:  Real: 122  Fake: 111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH02LJigXsRX"
      },
      "source": [
        "samples=[]\n",
        "label_lists=[] \n",
        "\n",
        "#Function to calculate Optical flow\n",
        "\n",
        "def get_opticalflow(file,frame_per_video) :\n",
        "  # The video feed is read in as a VideoCapture object\n",
        "  cap = cv.VideoCapture(file)\n",
        "\n",
        "  #splitting the file path to get the names of the videos\n",
        "  #change the split function according to your file path\n",
        "  temp_video = file.split('/')[-1]\n",
        "\n",
        "  #Change the path to Gobal_metadata.csv file accordingly\n",
        "  labels = pd.read_csv('/content/drive/MyDrive/Gobal_metadata.csv',names=header_list)\n",
        "\n",
        "  #getting the labels from Gobal_metadata.csv file\n",
        "  label = labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "  if(label == 'FAKE'):\n",
        "    label = 0\n",
        "  if(label == 'REAL'):\n",
        "    label = 1\n",
        "  \n",
        "  # ret = a boolean return value from\n",
        "  # getting the frame, first_frame = the\n",
        "  # first frame in the entire video sequence\n",
        "  ret, first_frame = cap.read()\n",
        "\n",
        "  # Converts frame to grayscale because we\n",
        "  # only need the luminance channel for\n",
        "  # detecting edges - less computationally\n",
        "  # expensive\n",
        "  prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Creates an image filled with zero\n",
        "  # intensities with the same dimensions\n",
        "  # as the frame\n",
        "  mask = np.zeros_like(first_frame)\n",
        "\n",
        "  #setting the frame count to 0\n",
        "  count=0\n",
        "  # Sets image saturation to maximum\n",
        "  mask[..., 1] = 255\n",
        "  \n",
        "  while(cap.isOpened()):\n",
        "    #appending the labels of the frames\n",
        "    label_lists.append(label)\n",
        "\n",
        "    # ret = a boolean return value from getting\n",
        "    # the frame, frame = the current frame being\n",
        "    # projected in the video\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    # Converts each frame to grayscale - we previously\n",
        "    # only converted the first frame to grayscale\n",
        "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Calculates dense optical flow by Farneback method\n",
        "    flow = cv.calcOpticalFlowFarneback(prev_gray, gray,\n",
        "                    None,\n",
        "                    0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    \n",
        "    # Computes the magnitude and angle of the 2D vectors\n",
        "    magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    \n",
        "    # Sets image hue according to the optical flow\n",
        "    # direction\n",
        "    mask[..., 0] = angle * 180 / np.pi / 2\n",
        "    \n",
        "    # Sets image value according to the optical flow\n",
        "    # magnitude (normalized)\n",
        "    mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)\n",
        "    \n",
        "    # Converts HSV to RGB (BGR) color representation\n",
        "    rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)\n",
        "    \n",
        "    #appending the rgb frames to samples\n",
        "    samples.append(rgb)\n",
        " \n",
        "    # Updates previous frame\n",
        "    prev_gray = gray\n",
        "\n",
        "    #updates the frame count\n",
        "    count=count+1\n",
        "    \n",
        "    #if the frame_count limit is reached the loop breaks and moves to next video\n",
        "    if count==frame_per_video:\n",
        "      break\n",
        "\n",
        "  # The following frees up resources and\n",
        "  # closes all windows\n",
        "  cap.release()\n",
        "  cv.destroyAllWindows()\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01FSAMxcX1pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da56b9f0-5ddc-4228-f956-ac28d010e195"
      },
      "source": [
        "#defining the number of frames to retrieve from each video\n",
        "frame_per_video=148\n",
        "\n",
        "#Generating the optical flow of the videos in train_videos\n",
        "for i in train_videos:\n",
        "  get_opticalflow(i,frame_per_video)\n",
        "\n",
        "#converting the samples(frames list) to numpy array\n",
        "x=np.array(samples) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x:\n",
            "(4640, 112, 112, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBFa1Eve_Brk"
      },
      "source": [
        "y = label_lists\n",
        "\n",
        "#creating the training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=42, test_size=0.2, stratify = y)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzXXpagwd6YI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4889e442-73ec-4b46-ee41-c01b0c49c254"
      },
      "source": [
        "#printing the shape of X_train\n",
        "print(X_train.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3712, 1, 4608)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEG9hlIQeO09"
      },
      "source": [
        "# creating dummies of target variable for train and validation set\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MUDBKgjeYoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb4c439-5629-4b05-a510-7677f42120d6"
      },
      "source": [
        "# creating the base model of pre-trained VGG16 model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfFPBKbKe_hK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6bce209-c865-4407-fbaf-199999bd14a2"
      },
      "source": [
        "# extracting features for training frames\n",
        "X_train = base_model.predict(X_train)\n",
        "# extracting features for validation frames\n",
        "X_test = base_model.predict(X_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3712, 3, 3, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INDBhHwFfhxY"
      },
      "source": [
        "# reshaping the training as well as validation frames in single dimension\n",
        "# change the shapes of X_train and X_test accordingly\n",
        "X_train = X_train.reshape(X_train.shape[0], 3*3*512)\n",
        "X_test = X_test.reshape(X_test.shape[0], 3*3*512)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UA2nvQYfsEa"
      },
      "source": [
        "# normalizing the pixel values\n",
        "max = X_train.max()\n",
        "X_train = X_train/max\n",
        "X_test = X_test/max"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcUdS0_Xz5l-"
      },
      "source": [
        "X_train = X_train.reshape(len(X_train), 1, X_train.shape[1])\n",
        "X_test = X_test.reshape(len(X_test), 1, X_test.shape[1])\n",
        "y_train_new=y_train.to_numpy()\n",
        "y_test_new=y_test.to_numpy()\n",
        "y_test_new = y_test_new.reshape(len(y_test_new), 1, y_test_new.shape[1])\n",
        "y_train_new = y_train_new.reshape(len(y_train_new), 1, y_train_new.shape[1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et8h_Zfvfyty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09ba6c4-7159-484f-dd0c-c3337d803fda"
      },
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Recurrent layer\n",
        "model.add(LSTM(128,input_shape=(X_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(LSTM(128,input_shape=(X_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnozyxvPf798"
      },
      "source": [
        "# defining a function to save the weights of best model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f95MUwc4f_y9"
      },
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fz79x-JgKeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629a9fba-630f-4545-b9ac-2169e24f1b18"
      },
      "source": [
        "# training the model\n",
        "model.fit(X_train, y_train_new, epochs=30, validation_data=(X_test, y_test_new), callbacks=[mcp_save], batch_size=128)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "29/29 [==============================] - 3s 35ms/step - loss: 0.6934 - accuracy: 0.4946 - val_loss: 0.6931 - val_accuracy: 0.4989\n",
            "Epoch 2/30\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.6915 - accuracy: 0.5286 - val_loss: 0.6915 - val_accuracy: 0.5172\n",
            "Epoch 3/30\n",
            "29/29 [==============================] - 0s 14ms/step - loss: 0.6675 - accuracy: 0.5962 - val_loss: 0.6831 - val_accuracy: 0.5647\n",
            "Epoch 4/30\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.6425 - accuracy: 0.6514 - val_loss: 0.6719 - val_accuracy: 0.5841\n",
            "Epoch 5/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.6033 - accuracy: 0.6867 - val_loss: 0.6890 - val_accuracy: 0.5938\n",
            "Epoch 6/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.5395 - accuracy: 0.7346 - val_loss: 0.7067 - val_accuracy: 0.6034\n",
            "Epoch 7/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.7839 - val_loss: 0.7815 - val_accuracy: 0.6164\n",
            "Epoch 8/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8284 - val_loss: 0.8455 - val_accuracy: 0.6121\n",
            "Epoch 9/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.3131 - accuracy: 0.8640 - val_loss: 0.9539 - val_accuracy: 0.6164\n",
            "Epoch 10/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.2470 - accuracy: 0.9011 - val_loss: 0.9356 - val_accuracy: 0.6175\n",
            "Epoch 11/30\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.2320 - accuracy: 0.9060 - val_loss: 0.9600 - val_accuracy: 0.6121\n",
            "Epoch 12/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1660 - accuracy: 0.9402 - val_loss: 1.2576 - val_accuracy: 0.6034\n",
            "Epoch 13/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1511 - accuracy: 0.9442 - val_loss: 1.4776 - val_accuracy: 0.6088\n",
            "Epoch 14/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.1205 - accuracy: 0.9539 - val_loss: 1.5306 - val_accuracy: 0.6099\n",
            "Epoch 15/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0865 - accuracy: 0.9688 - val_loss: 1.7159 - val_accuracy: 0.6088\n",
            "Epoch 16/30\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9723 - val_loss: 1.9288 - val_accuracy: 0.6228\n",
            "Epoch 17/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0685 - accuracy: 0.9747 - val_loss: 1.6853 - val_accuracy: 0.6056\n",
            "Epoch 18/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0773 - accuracy: 0.9706 - val_loss: 1.7596 - val_accuracy: 0.5970\n",
            "Epoch 19/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0705 - accuracy: 0.9763 - val_loss: 1.8763 - val_accuracy: 0.6088\n",
            "Epoch 20/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0498 - accuracy: 0.9838 - val_loss: 2.0799 - val_accuracy: 0.6207\n",
            "Epoch 21/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0474 - accuracy: 0.9849 - val_loss: 1.7211 - val_accuracy: 0.6153\n",
            "Epoch 22/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0367 - accuracy: 0.9890 - val_loss: 2.3934 - val_accuracy: 0.5959\n",
            "Epoch 23/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0516 - accuracy: 0.9825 - val_loss: 1.6833 - val_accuracy: 0.6153\n",
            "Epoch 24/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0415 - accuracy: 0.9855 - val_loss: 2.2711 - val_accuracy: 0.6013\n",
            "Epoch 25/30\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 0.9833 - val_loss: 1.9483 - val_accuracy: 0.6099\n",
            "Epoch 26/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0406 - accuracy: 0.9863 - val_loss: 2.2778 - val_accuracy: 0.6185\n",
            "Epoch 27/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 2.5930 - val_accuracy: 0.6121\n",
            "Epoch 28/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0471 - accuracy: 0.9838 - val_loss: 1.7411 - val_accuracy: 0.6034\n",
            "Epoch 29/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9873 - val_loss: 2.2903 - val_accuracy: 0.6099\n",
            "Epoch 30/30\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 2.0610 - val_accuracy: 0.6336\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd07e56db50>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDCTKdz8AzvC"
      },
      "source": [
        "Evaluating our Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-QNh4LuhuIm"
      },
      "source": [
        "# loading the trained weights \n",
        "#Enter the path accordingly\n",
        "model.load_weights(\"weight.hdf5\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrjW_sbdhzYJ"
      },
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#valid_label.clear\n",
        "#del df\n",
        "#del y"
      ],
      "metadata": {
        "id": "aaf1r0dHB1Rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3PFQUIO_q_H"
      },
      "source": [
        "# creating dataframe for actual labels of the valid_videos\n",
        "valid_label =[]\n",
        "\n",
        "for video_file in valid_videos :\n",
        "    count = 0\n",
        "    videoFile = video_file\n",
        "    cap = cv2.VideoCapture(video_file)   # capturing the video from the given path\n",
        "\n",
        "    # Splitting the file path of videos to get their names \n",
        "    #can be changed accordingly\n",
        "    temp_video = video_file.split('/')[-1] \n",
        "\n",
        "    # Change the path to Gobal_metadata.csv accordingly\n",
        "    labels = pd.read_csv('/content/drive/MyDrive/Gobal_metadata.csv',names=header_list)\n",
        "    label = labels.iloc[(labels.loc[labels[\"file\"] == temp_video].index.values[0]),1]\n",
        "    if(label == 'FAKE'):\n",
        "      label = 0\n",
        "    if(label == 'REAL'):\n",
        "      label = 1\n",
        "    label_str = str(label)\n",
        "    valid_label.append(label_str)\n",
        "            \n",
        "df = pd.DataFrame(valid_label)\n",
        "y = pd.get_dummies(df)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYZahHf0Cep5"
      },
      "source": [
        "While re-running the code, execute predit.clear to clear the list of previously predicted labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQaT8hszh4do"
      },
      "source": [
        "predict=[]\n",
        "\n",
        "def predicting(file,frame_per_video) :\n",
        "  prediction_images=[]\n",
        "  count=0 \n",
        "  # The video feed is read in as\n",
        "  # a VideoCapture object\n",
        "  cap = cv.VideoCapture(file)\n",
        "  \n",
        "  # ret = a boolean return value from\n",
        "  # getting the frame, first_frame = the\n",
        "  # first frame in the entire video sequence\n",
        "  ret, first_frame = cap.read()\n",
        "\n",
        "  # Converts frame to grayscale because we\n",
        "  # only need the luminance channel for\n",
        "  # detecting edges - less computationally\n",
        "  # expensive\n",
        "  prev_gray = cv.cvtColor(first_frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Creates an image filled with zero\n",
        "  # intensities with the same dimensions\n",
        "  # as the frame\n",
        "  mask = np.zeros_like(first_frame)\n",
        "  \n",
        "  # Sets image saturation to maximum\n",
        "  mask[..., 1] = 255\n",
        "  \n",
        "  while(cap.isOpened()):\n",
        "    \n",
        "    # ret = a boolean return value from getting\n",
        "    # the frame, frame = the current frame being\n",
        "    # projected in the video\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    # Opens a new window and displays the input\n",
        "    # frame\n",
        "    #cv2_imshow(frame)\n",
        "    \n",
        "    # Converts each frame to grayscale - we previously\n",
        "    # only converted the first frame to grayscale\n",
        "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Calculates dense optical flow by Farneback method\n",
        "    flow = cv.calcOpticalFlowFarneback(prev_gray, gray,\n",
        "                    None,\n",
        "                    0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "    \n",
        "    # Computes the magnitude and angle of the 2D vectors\n",
        "    magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "    \n",
        "    # Sets image hue according to the optical flow\n",
        "    # direction\n",
        "    mask[..., 0] = angle * 180 / np.pi / 2\n",
        "    \n",
        "    # Sets image value according to the optical flow\n",
        "    # magnitude (normalized)\n",
        "    mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)\n",
        "    \n",
        "    # Converts HSV to RGB (BGR) color representation\n",
        "    rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)\n",
        "    \n",
        "    #appending the rgb images \n",
        "    prediction_images.append(rgb)\n",
        "    \n",
        "    # Updates previous frame\n",
        "    prev_gray = gray\n",
        "    count=count+1\n",
        "    # Frames are read by intervals of 1 millisecond. The\n",
        "    # programs breaks out of the while loop when the\n",
        "    # user presses the 'q' key\n",
        "    if count==frame_per_video:\n",
        "      break\n",
        "\n",
        "  # The following frees up resources and closes all windows\n",
        "  cap.release()\n",
        "  cv.destroyAllWindows()\n",
        "  # converting all the frames for a test video into numpy array\n",
        "  prediction_images = np.array(prediction_images)\n",
        "\n",
        "  # extracting features using pre-trained model\n",
        "  prediction_images = base_model.predict(prediction_images)\n",
        " \n",
        "  # converting features in one dimensional array\n",
        "  prediction_images = prediction_images.reshape(prediction_images.shape[0], 3*3*512)\n",
        "\n",
        "  prediction_images = prediction_images.reshape(len(prediction_images), 1, prediction_images.shape[1])\n",
        "\n",
        "  # predicting tags for each array\n",
        "  prediction = np.argmax(model.predict(prediction_images),axis=-1)\n",
        "\n",
        "  prediction_new= pd.DataFrame(prediction)\n",
        "  g = s.mode(prediction_new)[0][0]\n",
        "  k=g[0]\n",
        "  # appending the mode of predictions in predict list to assign the tag to the video\n",
        "  predict.append(y.columns.values[k].split('_')[-1])\n",
        "  \n",
        "  "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict.clear"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDgCtYCilSfZ",
        "outputId": "79df988a-9911-46e9-b858-022d1f7cb1aa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function list.clear>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyS9oKGDTWbx"
      },
      "source": [
        "#predicting the videos over the trained model\n",
        "for i in valid_videos :\n",
        "  predicting(i,frame_per_video)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLpAQ2lqIq7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7307f374-214b-450a-debc-a2e736e910bc"
      },
      "source": [
        "accuracy_metric=accuracy_score(predict, valid_label)\n",
        "print(\"Accuracy score : \", accuracy_metric*100)\n",
        "\n",
        "precision_metric=precision_score(valid_label, predict, average = \"macro\")\n",
        "print(\"Precision score : \", precision_metric*100)\n",
        "\n",
        "recall_metric = recall_score(valid_label, predict, average = \"macro\")\n",
        "print(\"Recall score : \",recall_metric*100)\n",
        "\n",
        "\n",
        "f1_metric = f1_score(valid_label, predict, average = \"macro\")\n",
        "print(\"F1 score : \", f1_metric*100)\n",
        "\n",
        "# calculate roc curve\n",
        "#fpr, tpr, thresholds = roc_curve(valid_label, predict)\n",
        "# calculate AUC\n",
        "auc = roc_auc_score(valid_label, predict)\n",
        "print(\"ROC AUC score : \",auc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score :  53.648068669527895\n",
            "Precision score :  62.03612479474548\n",
            "Recall score :  55.41278983901935\n",
            "F1 score :  47.27623198122696\n",
            "ROC AUC score :  0.5541278983901934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:546: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  y_score = check_array(y_score, ensure_2d=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_label = [int(i) for i in valid_label]\n",
        "predict = [int(i) for i in predict]"
      ],
      "metadata": {
        "id": "YMim1lauOy6P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_fpr, lr_tpr, _ = roc_curve(valid_label, predict)\n",
        "plt.subplots(1, figsize=(6,6))\n",
        "plt.title('ROC curve of the model')\n",
        "plt.plot(lr_fpr, lr_tpr, color=\"#db7807\")\n",
        "plt.plot([0, 1], ls=\"--\", color=\"orange\")\n",
        "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "sw7oSUXTTark",
        "outputId": "bcd4ea4d-8af0-4150-c721-776f27a09c7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}